{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Rafael\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Rafael\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Baixar recursos do NLTK\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "\n",
    "# Função para extrair texto de PDFs\n",
    "def pdf_para_txt(caminho_pdf):\n",
    "    with open(caminho_pdf, \"rb\") as f:\n",
    "        leitor = PyPDF2.PdfReader(f)\n",
    "        texto = \"\"\n",
    "        for pagina in range(len(leitor.pages)):\n",
    "            texto += leitor.pages[pagina].extract_text()\n",
    "    return texto\n",
    "\n",
    "# Diretórios com os PDFs\n",
    "diretorios = {\n",
    "    'poesia': 'pdfs/poesia/',\n",
    "    'prosa': 'pdfs/prosa/',\n",
    "    'jornalismo': 'pdfs/jornalismo/'\n",
    "}\n",
    "\n",
    "# Função para limpar e remover stopwords\n",
    "def limpar_texto(texto):\n",
    "    texto = texto.replace(\"\\n\", \" \")\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    palavras = nltk.word_tokenize(texto.lower())\n",
    "    palavras_limpa = [palavra for palavra in palavras if palavra.isalnum() and palavra not in stop_words]\n",
    "    return \" \".join(palavras_limpa)\n",
    "\n",
    "import os\n",
    "\n",
    "# Extraindo textos e gerando classes\n",
    "textos = []\n",
    "classes = []\n",
    "\n",
    "for classe, caminho in diretorios.items():\n",
    "    for arquivo in os.listdir(caminho):\n",
    "        if arquivo.endswith(\".pdf\"):\n",
    "            texto = pdf_para_txt(os.path.join(caminho, arquivo))\n",
    "            texto_limpo = limpar_texto(texto)\n",
    "            textos.append(texto_limpo)\n",
    "            classes.append(classe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz BoW:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Vocabulário:  ['00' '01' '02' ... '⁹¹the' '⁹⁰but' '⁹⁰no']\n",
      "Classes:  ['poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'poesia', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'prosa', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo', 'jornalismo']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Criando a matriz Bag of Words\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(textos)\n",
    "\n",
    "print(\"Matriz BoW: \", X.toarray())\n",
    "print(\"Vocabulário: \", vectorizer.get_feature_names_out())\n",
    "print(\"Classes: \", classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n",
      "Melhores hiperparâmetros para Árvore de decisão: {'criterion': 'entropy', 'max_depth': 3, 'splitter': 'best'}\n",
      "Melhor acurácia: 0.9667\n",
      "Configuração de Hiperparâmetros 1: {'criterion': 'gini', 'max_depth': None, 'splitter': 'best'}\n",
      "  Fold 1: Acurácia = 0.9333, F1-score = 0.9333\n",
      "  Fold 2: Acurácia = 0.9333, F1-score = 0.9333\n",
      "  Fold 3: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Fold 4: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 5: Acurácia = 0.9333, F1-score = 0.9333\n",
      "  Fold 6: Acurácia = 0.8333, F1-score = 0.8222\n",
      "  Fold 7: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 8: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 9: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Fold 10: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Acurácia média: 0.9533, Desvio padrão: 0.0476\n",
      "  F1-score médio: 0.9522, Desvio padrão: 0.0504\n",
      "--------------------------------------------------\n",
      "Configuração de Hiperparâmetros 2: {'criterion': 'gini', 'max_depth': None, 'splitter': 'random'}\n",
      "  Fold 1: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 2: Acurácia = 0.9333, F1-score = 0.9327\n",
      "  Fold 3: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Fold 4: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 5: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 6: Acurácia = 0.8667, F1-score = 0.8611\n",
      "  Fold 7: Acurácia = 0.9000, F1-score = 0.8997\n",
      "  Fold 8: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 9: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Fold 10: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Acurácia média: 0.9533, Desvio padrão: 0.0400\n",
      "  F1-score médio: 0.9526, Desvio padrão: 0.0413\n",
      "--------------------------------------------------\n",
      "Configuração de Hiperparâmetros 3: {'criterion': 'gini', 'max_depth': 1, 'splitter': 'best'}\n",
      "  Fold 1: Acurácia = 0.6667, F1-score = 0.5556\n",
      "  Fold 2: Acurácia = 0.6667, F1-score = 0.5556\n",
      "  Fold 3: Acurácia = 0.6667, F1-score = 0.5556\n",
      "  Fold 4: Acurácia = 0.6667, F1-score = 0.5556\n",
      "  Fold 5: Acurácia = 0.6667, F1-score = 0.5556\n",
      "  Fold 6: Acurácia = 0.6667, F1-score = 0.5556\n",
      "  Fold 7: Acurácia = 0.6667, F1-score = 0.5556\n",
      "  Fold 8: Acurácia = 0.6667, F1-score = 0.5556\n",
      "  Fold 9: Acurácia = 0.6667, F1-score = 0.5556\n",
      "  Fold 10: Acurácia = 0.6667, F1-score = 0.5556\n",
      "  Acurácia média: 0.6667, Desvio padrão: 0.0000\n",
      "  F1-score médio: 0.5556, Desvio padrão: 0.0000\n",
      "--------------------------------------------------\n",
      "Configuração de Hiperparâmetros 4: {'criterion': 'gini', 'max_depth': 1, 'splitter': 'random'}\n",
      "  Fold 1: Acurácia = 0.6667, F1-score = 0.5556\n",
      "  Fold 2: Acurácia = 0.6667, F1-score = 0.5556\n",
      "  Fold 3: Acurácia = 0.6667, F1-score = 0.5556\n",
      "  Fold 4: Acurácia = 0.6667, F1-score = 0.5556\n",
      "  Fold 5: Acurácia = 0.6667, F1-score = 0.5556\n",
      "  Fold 6: Acurácia = 0.6667, F1-score = 0.5556\n",
      "  Fold 7: Acurácia = 0.6667, F1-score = 0.5556\n",
      "  Fold 8: Acurácia = 0.6667, F1-score = 0.5556\n",
      "  Fold 9: Acurácia = 0.6667, F1-score = 0.5556\n",
      "  Fold 10: Acurácia = 0.6667, F1-score = 0.5556\n",
      "  Acurácia média: 0.6667, Desvio padrão: 0.0000\n",
      "  F1-score médio: 0.5556, Desvio padrão: 0.0000\n",
      "--------------------------------------------------\n",
      "Configuração de Hiperparâmetros 5: {'criterion': 'gini', 'max_depth': 3, 'splitter': 'best'}\n",
      "  Fold 1: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 2: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 3: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Fold 4: Acurácia = 0.9333, F1-score = 0.9333\n",
      "  Fold 5: Acurácia = 0.9000, F1-score = 0.8997\n",
      "  Fold 6: Acurácia = 0.8333, F1-score = 0.8222\n",
      "  Fold 7: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 8: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 9: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Fold 10: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Acurácia média: 0.9533, Desvio padrão: 0.0499\n",
      "  F1-score médio: 0.9522, Desvio padrão: 0.0526\n",
      "--------------------------------------------------\n",
      "Configuração de Hiperparâmetros 6: {'criterion': 'gini', 'max_depth': 3, 'splitter': 'random'}\n",
      "  Fold 1: Acurácia = 0.7333, F1-score = 0.6825\n",
      "  Fold 2: Acurácia = 0.8667, F1-score = 0.8611\n",
      "  Fold 3: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Fold 4: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 5: Acurácia = 0.9333, F1-score = 0.9327\n",
      "  Fold 6: Acurácia = 0.8667, F1-score = 0.8611\n",
      "  Fold 7: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 8: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 9: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 10: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Acurácia média: 0.9233, Desvio padrão: 0.0761\n",
      "  F1-score médio: 0.9170, Desvio padrão: 0.0898\n",
      "--------------------------------------------------\n",
      "Configuração de Hiperparâmetros 7: {'criterion': 'entropy', 'max_depth': None, 'splitter': 'best'}\n",
      "  Fold 1: Acurácia = 0.9333, F1-score = 0.9333\n",
      "  Fold 2: Acurácia = 0.9333, F1-score = 0.9332\n",
      "  Fold 3: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Fold 4: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 5: Acurácia = 0.9000, F1-score = 0.8997\n",
      "  Fold 6: Acurácia = 0.9000, F1-score = 0.8977\n",
      "  Fold 7: Acurácia = 0.9333, F1-score = 0.9333\n",
      "  Fold 8: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 9: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Fold 10: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Acurácia média: 0.9533, Desvio padrão: 0.0371\n",
      "  F1-score médio: 0.9531, Desvio padrão: 0.0375\n",
      "--------------------------------------------------\n",
      "Configuração de Hiperparâmetros 8: {'criterion': 'entropy', 'max_depth': None, 'splitter': 'random'}\n",
      "  Fold 1: Acurácia = 0.9000, F1-score = 0.8977\n",
      "  Fold 2: Acurácia = 0.6333, F1-score = 0.5244\n",
      "  Fold 3: Acurácia = 0.9333, F1-score = 0.9327\n",
      "  Fold 4: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 5: Acurácia = 0.9333, F1-score = 0.9327\n",
      "  Fold 6: Acurácia = 0.9000, F1-score = 0.8977\n",
      "  Fold 7: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 8: Acurácia = 0.8333, F1-score = 0.8295\n",
      "  Fold 9: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Fold 10: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Acurácia média: 0.9067, Desvio padrão: 0.1031\n",
      "  F1-score médio: 0.8948, Desvio padrão: 0.1330\n",
      "--------------------------------------------------\n",
      "Configuração de Hiperparâmetros 9: {'criterion': 'entropy', 'max_depth': 1, 'splitter': 'best'}\n",
      "  Fold 1: Acurácia = 0.6333, F1-score = 0.5308\n",
      "  Fold 2: Acurácia = 0.6667, F1-score = 0.5556\n",
      "  Fold 3: Acurácia = 0.6667, F1-score = 0.5556\n",
      "  Fold 4: Acurácia = 0.6667, F1-score = 0.5556\n",
      "  Fold 5: Acurácia = 0.6667, F1-score = 0.5556\n",
      "  Fold 6: Acurácia = 0.6667, F1-score = 0.5556\n",
      "  Fold 7: Acurácia = 0.6667, F1-score = 0.5556\n",
      "  Fold 8: Acurácia = 0.6667, F1-score = 0.5556\n",
      "  Fold 9: Acurácia = 0.6667, F1-score = 0.5556\n",
      "  Fold 10: Acurácia = 0.6667, F1-score = 0.5556\n",
      "  Acurácia média: 0.6633, Desvio padrão: 0.0100\n",
      "  F1-score médio: 0.5531, Desvio padrão: 0.0074\n",
      "--------------------------------------------------\n",
      "Configuração de Hiperparâmetros 10: {'criterion': 'entropy', 'max_depth': 1, 'splitter': 'random'}\n",
      "  Fold 1: Acurácia = 0.6667, F1-score = 0.5556\n",
      "  Fold 2: Acurácia = 0.6667, F1-score = 0.5556\n",
      "  Fold 3: Acurácia = 0.6667, F1-score = 0.5556\n",
      "  Fold 4: Acurácia = 0.6333, F1-score = 0.5308\n",
      "  Fold 5: Acurácia = 0.6667, F1-score = 0.5556\n",
      "  Fold 6: Acurácia = 0.6667, F1-score = 0.5556\n",
      "  Fold 7: Acurácia = 0.6667, F1-score = 0.5556\n",
      "  Fold 8: Acurácia = 0.6667, F1-score = 0.5556\n",
      "  Fold 9: Acurácia = 0.6667, F1-score = 0.5556\n",
      "  Fold 10: Acurácia = 0.6667, F1-score = 0.5556\n",
      "  Acurácia média: 0.6633, Desvio padrão: 0.0100\n",
      "  F1-score médio: 0.5531, Desvio padrão: 0.0074\n",
      "--------------------------------------------------\n",
      "Configuração de Hiperparâmetros 11: {'criterion': 'entropy', 'max_depth': 3, 'splitter': 'best'}\n",
      "  Fold 1: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 2: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 3: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Fold 4: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Fold 5: Acurácia = 0.9000, F1-score = 0.8997\n",
      "  Fold 6: Acurácia = 0.9000, F1-score = 0.8977\n",
      "  Fold 7: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 8: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 9: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Fold 10: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Acurácia média: 0.9667, Desvio padrão: 0.0365\n",
      "  F1-score médio: 0.9664, Desvio padrão: 0.0370\n",
      "--------------------------------------------------\n",
      "Configuração de Hiperparâmetros 12: {'criterion': 'entropy', 'max_depth': 3, 'splitter': 'random'}\n",
      "  Fold 1: Acurácia = 0.9000, F1-score = 0.8977\n",
      "  Fold 2: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 3: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 4: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 5: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 6: Acurácia = 0.8667, F1-score = 0.8611\n",
      "  Fold 7: Acurácia = 0.9000, F1-score = 0.8997\n",
      "  Fold 8: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Fold 9: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 10: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Acurácia média: 0.9500, Desvio padrão: 0.0428\n",
      "  F1-score médio: 0.9491, Desvio padrão: 0.0442\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import make_scorer, accuracy_score, f1_score\n",
    "\n",
    "# Criando o modelo base\n",
    "modelo = DecisionTreeClassifier()\n",
    "\n",
    "# Configuração de hiperparâmetros para teste\n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'splitter': ['best', 'random'],\n",
    "    'max_depth': [None, 1, 3]\n",
    "}\n",
    "\n",
    "# Métricas para otimização\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'f1_weighted': make_scorer(f1_score, average='weighted'),\n",
    "}\n",
    "\n",
    "# Configurando o GridSearchCV com validação cruzada\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=modelo,\n",
    "    param_grid=param_grid,\n",
    "    scoring=scoring,\n",
    "    refit='accuracy',\n",
    "    cv=10,  # Validação cruzada estratificada com 10 folds\n",
    "    verbose=2,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "# Treinando o modelo com GridSearch\n",
    "grid_search.fit(X, classes)\n",
    "\n",
    "# Exibindo os melhores hiperparâmetros e resultados\n",
    "print(\"Melhores hiperparâmetros para Árvore de decisão:\", grid_search.best_params_)\n",
    "print(f\"Melhor acurácia: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Obtendo os resultados detalhados\n",
    "resultados = grid_search.cv_results_\n",
    "\n",
    "# Iterar sobre cada combinação de hiperparâmetros\n",
    "for i in range(len(resultados['params'])):\n",
    "    print(f\"Configuração de Hiperparâmetros {i+1}: {resultados['params'][i]}\")\n",
    "\n",
    "    # Métricas para cada fold\n",
    "    for fold in range(10):  # 10 folds\n",
    "        acuracia_fold = resultados[f'split{fold}_test_accuracy'][i]\n",
    "        f1_fold = resultados[f'split{fold}_test_f1_weighted'][i]\n",
    "        print(f\"  Fold {fold+1}: Acurácia = {acuracia_fold:.4f}, F1-score = {f1_fold:.4f}\")\n",
    "\n",
    "    # Métricas médias\n",
    "    acuracia_media = resultados['mean_test_accuracy'][i]\n",
    "    f1_media = resultados['mean_test_f1_weighted'][i]\n",
    "    acuracia_std = resultados['std_test_accuracy'][i]\n",
    "    f1_std = resultados['std_test_f1_weighted'][i]\n",
    "\n",
    "    print(f\"  Acurácia média: {acuracia_media:.4f}, Desvio padrão: {acuracia_std:.4f}\")\n",
    "    print(f\"  F1-score médio: {f1_media:.4f}, Desvio padrão: {f1_std:.4f}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n",
      "Melhores hiperparâmetros para KNN: {'algorithm': 'auto', 'n_neighbors': 7, 'weights': 'uniform'}\n",
      "Melhor acurácia: 0.9733\n",
      "Configuração de Hiperparâmetros 1: {'algorithm': 'auto', 'n_neighbors': 2, 'weights': 'uniform'}\n",
      "  Fold 1: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 2: Acurácia = 0.9000, F1-score = 0.8977\n",
      "  Fold 3: Acurácia = 0.9333, F1-score = 0.9327\n",
      "  Fold 4: Acurácia = 0.9333, F1-score = 0.9327\n",
      "  Fold 5: Acurácia = 0.8667, F1-score = 0.8611\n",
      "  Fold 6: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Fold 7: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 8: Acurácia = 0.9333, F1-score = 0.9327\n",
      "  Fold 9: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Fold 10: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Acurácia média: 0.9500, Desvio padrão: 0.0428\n",
      "  F1-score médio: 0.9490, Desvio padrão: 0.0442\n",
      "--------------------------------------------------\n",
      "Configuração de Hiperparâmetros 2: {'algorithm': 'auto', 'n_neighbors': 2, 'weights': 'distance'}\n",
      "  Fold 1: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 2: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 3: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 4: Acurácia = 0.9333, F1-score = 0.9327\n",
      "  Fold 5: Acurácia = 0.9000, F1-score = 0.8977\n",
      "  Fold 6: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Fold 7: Acurácia = 0.9333, F1-score = 0.9327\n",
      "  Fold 8: Acurácia = 0.9000, F1-score = 0.8997\n",
      "  Fold 9: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Fold 10: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Acurácia média: 0.9567, Desvio padrão: 0.0367\n",
      "  F1-score médio: 0.9563, Desvio padrão: 0.0371\n",
      "--------------------------------------------------\n",
      "Configuração de Hiperparâmetros 3: {'algorithm': 'auto', 'n_neighbors': 5, 'weights': 'uniform'}\n",
      "  Fold 1: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 2: Acurácia = 0.9333, F1-score = 0.9327\n",
      "  Fold 3: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 4: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 5: Acurácia = 0.9333, F1-score = 0.9327\n",
      "  Fold 6: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Fold 7: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Fold 8: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 9: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Fold 10: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Acurácia média: 0.9700, Desvio padrão: 0.0233\n",
      "  F1-score médio: 0.9698, Desvio padrão: 0.0236\n",
      "--------------------------------------------------\n",
      "Configuração de Hiperparâmetros 4: {'algorithm': 'auto', 'n_neighbors': 5, 'weights': 'distance'}\n",
      "  Fold 1: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 2: Acurácia = 0.9333, F1-score = 0.9327\n",
      "  Fold 3: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 4: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 5: Acurácia = 0.9333, F1-score = 0.9327\n",
      "  Fold 6: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Fold 7: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Fold 8: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 9: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Fold 10: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Acurácia média: 0.9700, Desvio padrão: 0.0233\n",
      "  F1-score médio: 0.9698, Desvio padrão: 0.0236\n",
      "--------------------------------------------------\n",
      "Configuração de Hiperparâmetros 5: {'algorithm': 'auto', 'n_neighbors': 7, 'weights': 'uniform'}\n",
      "  Fold 1: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 2: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 3: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 4: Acurácia = 0.9333, F1-score = 0.9327\n",
      "  Fold 5: Acurácia = 0.9333, F1-score = 0.9327\n",
      "  Fold 6: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Fold 7: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Fold 8: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 9: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Fold 10: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Acurácia média: 0.9733, Desvio padrão: 0.0249\n",
      "  F1-score médio: 0.9732, Desvio padrão: 0.0252\n",
      "--------------------------------------------------\n",
      "Configuração de Hiperparâmetros 6: {'algorithm': 'auto', 'n_neighbors': 7, 'weights': 'distance'}\n",
      "  Fold 1: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 2: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 3: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 4: Acurácia = 0.9333, F1-score = 0.9327\n",
      "  Fold 5: Acurácia = 0.9333, F1-score = 0.9327\n",
      "  Fold 6: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Fold 7: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Fold 8: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 9: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Fold 10: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Acurácia média: 0.9733, Desvio padrão: 0.0249\n",
      "  F1-score médio: 0.9732, Desvio padrão: 0.0252\n",
      "--------------------------------------------------\n",
      "Configuração de Hiperparâmetros 7: {'algorithm': 'ball_tree', 'n_neighbors': 2, 'weights': 'uniform'}\n",
      "  Fold 1: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 2: Acurácia = 0.9000, F1-score = 0.8977\n",
      "  Fold 3: Acurácia = 0.9333, F1-score = 0.9327\n",
      "  Fold 4: Acurácia = 0.9333, F1-score = 0.9327\n",
      "  Fold 5: Acurácia = 0.8667, F1-score = 0.8611\n",
      "  Fold 6: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Fold 7: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 8: Acurácia = 0.9333, F1-score = 0.9327\n",
      "  Fold 9: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Fold 10: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Acurácia média: 0.9500, Desvio padrão: 0.0428\n",
      "  F1-score médio: 0.9490, Desvio padrão: 0.0442\n",
      "--------------------------------------------------\n",
      "Configuração de Hiperparâmetros 8: {'algorithm': 'ball_tree', 'n_neighbors': 2, 'weights': 'distance'}\n",
      "  Fold 1: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 2: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 3: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 4: Acurácia = 0.9333, F1-score = 0.9327\n",
      "  Fold 5: Acurácia = 0.9000, F1-score = 0.8977\n",
      "  Fold 6: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Fold 7: Acurácia = 0.9333, F1-score = 0.9327\n",
      "  Fold 8: Acurácia = 0.9000, F1-score = 0.8997\n",
      "  Fold 9: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Fold 10: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Acurácia média: 0.9567, Desvio padrão: 0.0367\n",
      "  F1-score médio: 0.9563, Desvio padrão: 0.0371\n",
      "--------------------------------------------------\n",
      "Configuração de Hiperparâmetros 9: {'algorithm': 'ball_tree', 'n_neighbors': 5, 'weights': 'uniform'}\n",
      "  Fold 1: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 2: Acurácia = 0.9333, F1-score = 0.9327\n",
      "  Fold 3: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 4: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 5: Acurácia = 0.9333, F1-score = 0.9327\n",
      "  Fold 6: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Fold 7: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Fold 8: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 9: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Fold 10: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Acurácia média: 0.9700, Desvio padrão: 0.0233\n",
      "  F1-score médio: 0.9698, Desvio padrão: 0.0236\n",
      "--------------------------------------------------\n",
      "Configuração de Hiperparâmetros 10: {'algorithm': 'ball_tree', 'n_neighbors': 5, 'weights': 'distance'}\n",
      "  Fold 1: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 2: Acurácia = 0.9333, F1-score = 0.9327\n",
      "  Fold 3: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 4: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 5: Acurácia = 0.9333, F1-score = 0.9327\n",
      "  Fold 6: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Fold 7: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Fold 8: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 9: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Fold 10: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Acurácia média: 0.9700, Desvio padrão: 0.0233\n",
      "  F1-score médio: 0.9698, Desvio padrão: 0.0236\n",
      "--------------------------------------------------\n",
      "Configuração de Hiperparâmetros 11: {'algorithm': 'ball_tree', 'n_neighbors': 7, 'weights': 'uniform'}\n",
      "  Fold 1: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 2: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 3: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 4: Acurácia = 0.9333, F1-score = 0.9327\n",
      "  Fold 5: Acurácia = 0.9333, F1-score = 0.9327\n",
      "  Fold 6: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Fold 7: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Fold 8: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 9: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Fold 10: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Acurácia média: 0.9733, Desvio padrão: 0.0249\n",
      "  F1-score médio: 0.9732, Desvio padrão: 0.0252\n",
      "--------------------------------------------------\n",
      "Configuração de Hiperparâmetros 12: {'algorithm': 'ball_tree', 'n_neighbors': 7, 'weights': 'distance'}\n",
      "  Fold 1: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 2: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 3: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 4: Acurácia = 0.9333, F1-score = 0.9327\n",
      "  Fold 5: Acurácia = 0.9333, F1-score = 0.9327\n",
      "  Fold 6: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Fold 7: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Fold 8: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 9: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Fold 10: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Acurácia média: 0.9733, Desvio padrão: 0.0249\n",
      "  F1-score médio: 0.9732, Desvio padrão: 0.0252\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Criando o modelo base\n",
    "modelo = KNeighborsClassifier()\n",
    "\n",
    "# Configuração de hiperparâmetros para teste\n",
    "param_grid = {\n",
    "    'n_neighbors': [2, 5, 7],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'algorithm': ['auto', 'ball_tree']\n",
    "}\n",
    "\n",
    "# Configurando o GridSearchCV com validação cruzada\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=modelo,\n",
    "    param_grid=param_grid,\n",
    "    scoring=scoring,\n",
    "    refit='accuracy',\n",
    "    cv=10,  # Validação cruzada estratificada com 10 folds\n",
    "    verbose=2,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "# Treinando o modelo com GridSearch\n",
    "grid_search.fit(X, classes)\n",
    "\n",
    "# Exibindo os melhores hiperparâmetros e resultados\n",
    "print(\"Melhores hiperparâmetros para KNN:\", grid_search.best_params_)\n",
    "print(f\"Melhor acurácia: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Obtendo os resultados detalhados\n",
    "resultados = grid_search.cv_results_\n",
    "\n",
    "# Iterar sobre cada combinação de hiperparâmetros\n",
    "for i in range(len(resultados['params'])):\n",
    "    print(f\"Configuração de Hiperparâmetros {i+1}: {resultados['params'][i]}\")\n",
    "\n",
    "    # Métricas para cada fold\n",
    "    for fold in range(10):  # 10 folds\n",
    "        acuracia_fold = resultados[f'split{fold}_test_accuracy'][i]\n",
    "        f1_fold = resultados[f'split{fold}_test_f1_weighted'][i]\n",
    "        print(f\"  Fold {fold+1}: Acurácia = {acuracia_fold:.4f}, F1-score = {f1_fold:.4f}\")\n",
    "\n",
    "    # Métricas médias\n",
    "    acuracia_media = resultados['mean_test_accuracy'][i]\n",
    "    f1_media = resultados['mean_test_f1_weighted'][i]\n",
    "    acuracia_std = resultados['std_test_accuracy'][i]\n",
    "    f1_std = resultados['std_test_f1_weighted'][i]\n",
    "\n",
    "    print(f\"  Acurácia média: {acuracia_media:.4f}, Desvio padrão: {acuracia_std:.4f}\")\n",
    "    print(f\"  F1-score médio: {f1_media:.4f}, Desvio padrão: {f1_std:.4f}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Melhores hiperparâmetros para Naive Bayes: {'alpha': 0.1, 'fit_prior': True}\n",
      "Melhor acurácia: 0.9400\n",
      "Configuração de Hiperparâmetros 1: {'alpha': 0.1, 'fit_prior': True}\n",
      "  Fold 1: Acurácia = 0.9333, F1-score = 0.9327\n",
      "  Fold 2: Acurácia = 0.9333, F1-score = 0.9327\n",
      "  Fold 3: Acurácia = 0.9000, F1-score = 0.8977\n",
      "  Fold 4: Acurácia = 0.9000, F1-score = 0.8977\n",
      "  Fold 5: Acurácia = 0.9333, F1-score = 0.9327\n",
      "  Fold 6: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 7: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 8: Acurácia = 0.9333, F1-score = 0.9327\n",
      "  Fold 9: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 10: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Acurácia média: 0.9400, Desvio padrão: 0.0249\n",
      "  F1-score médio: 0.9392, Desvio padrão: 0.0257\n",
      "--------------------------------------------------\n",
      "Configuração de Hiperparâmetros 2: {'alpha': 0.1, 'fit_prior': False}\n",
      "  Fold 1: Acurácia = 0.9333, F1-score = 0.9327\n",
      "  Fold 2: Acurácia = 0.9333, F1-score = 0.9327\n",
      "  Fold 3: Acurácia = 0.9000, F1-score = 0.8977\n",
      "  Fold 4: Acurácia = 0.9000, F1-score = 0.8977\n",
      "  Fold 5: Acurácia = 0.9333, F1-score = 0.9327\n",
      "  Fold 6: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 7: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 8: Acurácia = 0.9333, F1-score = 0.9327\n",
      "  Fold 9: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 10: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Acurácia média: 0.9400, Desvio padrão: 0.0249\n",
      "  F1-score médio: 0.9392, Desvio padrão: 0.0257\n",
      "--------------------------------------------------\n",
      "Configuração de Hiperparâmetros 3: {'alpha': 0.5, 'fit_prior': True}\n",
      "  Fold 1: Acurácia = 0.8667, F1-score = 0.8611\n",
      "  Fold 2: Acurácia = 0.9333, F1-score = 0.9327\n",
      "  Fold 3: Acurácia = 0.8333, F1-score = 0.8222\n",
      "  Fold 4: Acurácia = 0.9000, F1-score = 0.8977\n",
      "  Fold 5: Acurácia = 0.8667, F1-score = 0.8611\n",
      "  Fold 6: Acurácia = 0.9333, F1-score = 0.9327\n",
      "  Fold 7: Acurácia = 0.9333, F1-score = 0.9327\n",
      "  Fold 8: Acurácia = 0.9333, F1-score = 0.9327\n",
      "  Fold 9: Acurácia = 0.9333, F1-score = 0.9327\n",
      "  Fold 10: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Acurácia média: 0.9100, Desvio padrão: 0.0396\n",
      "  F1-score médio: 0.9072, Desvio padrão: 0.0428\n",
      "--------------------------------------------------\n",
      "Configuração de Hiperparâmetros 4: {'alpha': 0.5, 'fit_prior': False}\n",
      "  Fold 1: Acurácia = 0.8667, F1-score = 0.8611\n",
      "  Fold 2: Acurácia = 0.9333, F1-score = 0.9327\n",
      "  Fold 3: Acurácia = 0.8333, F1-score = 0.8222\n",
      "  Fold 4: Acurácia = 0.9000, F1-score = 0.8977\n",
      "  Fold 5: Acurácia = 0.8667, F1-score = 0.8611\n",
      "  Fold 6: Acurácia = 0.9333, F1-score = 0.9327\n",
      "  Fold 7: Acurácia = 0.9333, F1-score = 0.9327\n",
      "  Fold 8: Acurácia = 0.9333, F1-score = 0.9327\n",
      "  Fold 9: Acurácia = 0.9333, F1-score = 0.9327\n",
      "  Fold 10: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Acurácia média: 0.9100, Desvio padrão: 0.0396\n",
      "  F1-score médio: 0.9072, Desvio padrão: 0.0428\n",
      "--------------------------------------------------\n",
      "Configuração de Hiperparâmetros 5: {'alpha': 1.0, 'fit_prior': True}\n",
      "  Fold 1: Acurácia = 0.8667, F1-score = 0.8611\n",
      "  Fold 2: Acurácia = 0.9333, F1-score = 0.9327\n",
      "  Fold 3: Acurácia = 0.8333, F1-score = 0.8222\n",
      "  Fold 4: Acurácia = 0.8667, F1-score = 0.8611\n",
      "  Fold 5: Acurácia = 0.8667, F1-score = 0.8611\n",
      "  Fold 6: Acurácia = 0.9000, F1-score = 0.8977\n",
      "  Fold 7: Acurácia = 0.9333, F1-score = 0.9327\n",
      "  Fold 8: Acurácia = 0.9333, F1-score = 0.9327\n",
      "  Fold 9: Acurácia = 0.9333, F1-score = 0.9327\n",
      "  Fold 10: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Acurácia média: 0.9033, Desvio padrão: 0.0407\n",
      "  F1-score médio: 0.9000, Desvio padrão: 0.0439\n",
      "--------------------------------------------------\n",
      "Configuração de Hiperparâmetros 6: {'alpha': 1.0, 'fit_prior': False}\n",
      "  Fold 1: Acurácia = 0.8667, F1-score = 0.8611\n",
      "  Fold 2: Acurácia = 0.9333, F1-score = 0.9327\n",
      "  Fold 3: Acurácia = 0.8333, F1-score = 0.8222\n",
      "  Fold 4: Acurácia = 0.8667, F1-score = 0.8611\n",
      "  Fold 5: Acurácia = 0.8667, F1-score = 0.8611\n",
      "  Fold 6: Acurácia = 0.9000, F1-score = 0.8977\n",
      "  Fold 7: Acurácia = 0.9333, F1-score = 0.9327\n",
      "  Fold 8: Acurácia = 0.9333, F1-score = 0.9327\n",
      "  Fold 9: Acurácia = 0.9333, F1-score = 0.9327\n",
      "  Fold 10: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Acurácia média: 0.9033, Desvio padrão: 0.0407\n",
      "  F1-score médio: 0.9000, Desvio padrão: 0.0439\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Criando o modelo base\n",
    "modelo = MultinomialNB()\n",
    "\n",
    "# Configuração de hiperparâmetros para teste\n",
    "param_grid = {\n",
    "    'alpha': [0.1, 0.5, 1.0],\n",
    "    'fit_prior': [True, False]\n",
    "}\n",
    "\n",
    "# Configurando o GridSearchCV com validação cruzada\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=modelo,\n",
    "    param_grid=param_grid,\n",
    "    scoring=scoring,\n",
    "    refit='accuracy',\n",
    "    cv=10,  # Validação cruzada estratificada com 10 folds\n",
    "    verbose=2,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "# Treinando o modelo com GridSearch\n",
    "grid_search.fit(X, classes)\n",
    "\n",
    "# Exibindo os melhores hiperparâmetros e resultados\n",
    "print(\"Melhores hiperparâmetros para Naive Bayes:\", grid_search.best_params_)\n",
    "print(f\"Melhor acurácia: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Obtendo os resultados detalhados\n",
    "resultados = grid_search.cv_results_\n",
    "\n",
    "# Iterar sobre cada combinação de hiperparâmetros\n",
    "for i in range(len(resultados['params'])):\n",
    "    print(f\"Configuração de Hiperparâmetros {i+1}: {resultados['params'][i]}\")\n",
    "\n",
    "    # Métricas para cada fold\n",
    "    for fold in range(10):  # 10 folds\n",
    "        acuracia_fold = resultados[f'split{fold}_test_accuracy'][i]\n",
    "        f1_fold = resultados[f'split{fold}_test_f1_weighted'][i]\n",
    "        print(f\"  Fold {fold+1}: Acurácia = {acuracia_fold:.4f}, F1-score = {f1_fold:.4f}\")\n",
    "\n",
    "    # Métricas médias\n",
    "    acuracia_media = resultados['mean_test_accuracy'][i]\n",
    "    f1_media = resultados['mean_test_f1_weighted'][i]\n",
    "    acuracia_std = resultados['std_test_accuracy'][i]\n",
    "    f1_std = resultados['std_test_f1_weighted'][i]\n",
    "\n",
    "    print(f\"  Acurácia média: {acuracia_media:.4f}, Desvio padrão: {acuracia_std:.4f}\")\n",
    "    print(f\"  F1-score médio: {f1_media:.4f}, Desvio padrão: {f1_std:.4f}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Melhores hiperparâmetros para Regressão logística: {'class_weight': None, 'solver': 'lbfgs'}\n",
      "Melhor acurácia: 0.9733\n",
      "Configuração de Hiperparâmetros 1: {'class_weight': None, 'solver': 'lbfgs'}\n",
      "  Fold 1: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 2: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 3: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Fold 4: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 5: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Fold 6: Acurácia = 0.8667, F1-score = 0.8611\n",
      "  Fold 7: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Fold 8: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 9: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Fold 10: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Acurácia média: 0.9733, Desvio padrão: 0.0389\n",
      "  F1-score médio: 0.9727, Desvio padrão: 0.0404\n",
      "--------------------------------------------------\n",
      "Configuração de Hiperparâmetros 2: {'class_weight': None, 'solver': 'saga'}\n",
      "  Fold 1: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 2: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 3: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Fold 4: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 5: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Fold 6: Acurácia = 0.8667, F1-score = 0.8611\n",
      "  Fold 7: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Fold 8: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 9: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Fold 10: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Acurácia média: 0.9733, Desvio padrão: 0.0389\n",
      "  F1-score médio: 0.9727, Desvio padrão: 0.0404\n",
      "--------------------------------------------------\n",
      "Configuração de Hiperparâmetros 3: {'class_weight': None, 'solver': 'liblinear'}\n",
      "  Fold 1: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 2: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 3: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Fold 4: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 5: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Fold 6: Acurácia = 0.8667, F1-score = 0.8611\n",
      "  Fold 7: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 8: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 9: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Fold 10: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Acurácia média: 0.9700, Desvio padrão: 0.0379\n",
      "  F1-score médio: 0.9694, Desvio padrão: 0.0394\n",
      "--------------------------------------------------\n",
      "Configuração de Hiperparâmetros 4: {'class_weight': 'balanced', 'solver': 'lbfgs'}\n",
      "  Fold 1: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 2: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 3: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Fold 4: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 5: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Fold 6: Acurácia = 0.8667, F1-score = 0.8611\n",
      "  Fold 7: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Fold 8: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 9: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Fold 10: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Acurácia média: 0.9733, Desvio padrão: 0.0389\n",
      "  F1-score médio: 0.9727, Desvio padrão: 0.0404\n",
      "--------------------------------------------------\n",
      "Configuração de Hiperparâmetros 5: {'class_weight': 'balanced', 'solver': 'saga'}\n",
      "  Fold 1: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 2: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 3: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Fold 4: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 5: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Fold 6: Acurácia = 0.8667, F1-score = 0.8611\n",
      "  Fold 7: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Fold 8: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 9: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Fold 10: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Acurácia média: 0.9733, Desvio padrão: 0.0389\n",
      "  F1-score médio: 0.9727, Desvio padrão: 0.0404\n",
      "--------------------------------------------------\n",
      "Configuração de Hiperparâmetros 6: {'class_weight': 'balanced', 'solver': 'liblinear'}\n",
      "  Fold 1: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 2: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 3: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Fold 4: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 5: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Fold 6: Acurácia = 0.8667, F1-score = 0.8611\n",
      "  Fold 7: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 8: Acurácia = 0.9667, F1-score = 0.9666\n",
      "  Fold 9: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Fold 10: Acurácia = 1.0000, F1-score = 1.0000\n",
      "  Acurácia média: 0.9700, Desvio padrão: 0.0379\n",
      "  F1-score médio: 0.9694, Desvio padrão: 0.0394\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Criando o modelo base\n",
    "modelo = LogisticRegression()\n",
    "\n",
    "# Configuração de hiperparâmetros para teste\n",
    "param_grid = {\n",
    "    'solver': ['lbfgs', 'saga', 'liblinear'],\n",
    "    'class_weight': [None, 'balanced'],\n",
    "}\n",
    "\n",
    "# Configurando o GridSearchCV com validação cruzada\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=modelo,\n",
    "    param_grid=param_grid,\n",
    "    scoring=scoring,\n",
    "    refit='accuracy',\n",
    "    cv=10,  # Validação cruzada estratificada com 10 folds\n",
    "    verbose=2,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "# Treinando o modelo com GridSearch\n",
    "grid_search.fit(X, classes)\n",
    "\n",
    "# Exibindo os melhores hiperparâmetros e resultados\n",
    "print(\"Melhores hiperparâmetros para Regressão logística:\", grid_search.best_params_)\n",
    "print(f\"Melhor acurácia: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Obtendo os resultados detalhados\n",
    "resultados = grid_search.cv_results_\n",
    "\n",
    "# Iterar sobre cada combinação de hiperparâmetros\n",
    "for i in range(len(resultados['params'])):\n",
    "    print(f\"Configuração de Hiperparâmetros {i+1}: {resultados['params'][i]}\")\n",
    "\n",
    "    # Métricas para cada fold\n",
    "    for fold in range(10):\n",
    "        acuracia_fold = resultados[f'split{fold}_test_accuracy'][i]\n",
    "        f1_fold = resultados[f'split{fold}_test_f1_weighted'][i]\n",
    "        print(f\"  Fold {fold+1}: Acurácia = {acuracia_fold:.4f}, F1-score = {f1_fold:.4f}\")\n",
    "\n",
    "    # Métricas médias\n",
    "    acuracia_media = resultados['mean_test_accuracy'][i]\n",
    "    f1_media = resultados['mean_test_f1_weighted'][i]\n",
    "    acuracia_std = resultados['std_test_accuracy'][i]\n",
    "    f1_std = resultados['std_test_f1_weighted'][i]\n",
    "\n",
    "    print(f\"  Acurácia média: {acuracia_media:.4f}, Desvio padrão: {acuracia_std:.4f}\")\n",
    "    print(f\"  F1-score médio: {f1_media:.4f}, Desvio padrão: {f1_std:.4f}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 8 candidates, totalling 80 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 26\u001b[0m\n\u001b[0;32m     15\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(\n\u001b[0;32m     16\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mmodelo,\n\u001b[0;32m     17\u001b[0m     param_grid\u001b[38;5;241m=\u001b[39mparam_grid,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     22\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     23\u001b[0m )\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Treinando o modelo com GridSearch\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Exibindo os melhores hiperparâmetros e resultados\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMelhores hiperparâmetros para Rede Neural MLP:\u001b[39m\u001b[38;5;124m\"\u001b[39m, grid_search\u001b[38;5;241m.\u001b[39mbest_params_)\n",
      "File \u001b[1;32md:\\Arquivos\\EngSoft\\IA\\trab\\bow\\.env\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Arquivos\\EngSoft\\IA\\trab\\bow\\.env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1019\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1013\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1014\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1015\u001b[0m     )\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1019\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1022\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1023\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32md:\\Arquivos\\EngSoft\\IA\\trab\\bow\\.env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1573\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1571\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1572\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1573\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Arquivos\\EngSoft\\IA\\trab\\bow\\.env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:965\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    958\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    959\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    960\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    961\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    962\u001b[0m         )\n\u001b[0;32m    963\u001b[0m     )\n\u001b[1;32m--> 965\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    966\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    981\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    984\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    985\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    986\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    987\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    988\u001b[0m     )\n",
      "File \u001b[1;32md:\\Arquivos\\EngSoft\\IA\\trab\\bow\\.env\\Lib\\site-packages\\sklearn\\utils\\parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     73\u001b[0m )\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Arquivos\\EngSoft\\IA\\trab\\bow\\.env\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[1;32md:\\Arquivos\\EngSoft\\IA\\trab\\bow\\.env\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32md:\\Arquivos\\EngSoft\\IA\\trab\\bow\\.env\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Criando o modelo base\n",
    "modelo = MLPClassifier()\n",
    "\n",
    "# Configuração de hiperparâmetros para teste\n",
    "param_grid = {\n",
    "    \"hidden_layer_sizes\": [(50,), (100,)],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'early_stopping': [True],\n",
    "}\n",
    "\n",
    "# Configurando o GridSearchCV com validação cruzada\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=modelo,\n",
    "    param_grid=param_grid,\n",
    "    scoring=scoring,\n",
    "    refit='accuracy',\n",
    "    cv=10,  # Validação cruzada estratificada com 10 folds\n",
    "    verbose=2,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "# Treinando o modelo com GridSearch\n",
    "grid_search.fit(X, classes)\n",
    "\n",
    "# Exibindo os melhores hiperparâmetros e resultados\n",
    "print(\"Melhores hiperparâmetros para Rede Neural MLP:\", grid_search.best_params_)\n",
    "print(f\"Melhor acurácia: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Obtendo os resultados detalhados\n",
    "resultados = grid_search.cv_results_\n",
    "\n",
    "# Iterar sobre cada combinação de hiperparâmetros\n",
    "for i in range(len(resultados['params'])):\n",
    "    print(f\"Configuração de Hiperparâmetros {i+1}: {resultados['params'][i]}\")\n",
    "\n",
    "    # Métricas para cada fold\n",
    "    for fold in range(10):  # 10 folds\n",
    "        acuracia_fold = resultados[f'split{fold}_test_accuracy'][i]\n",
    "        f1_fold = resultados[f'split{fold}_test_f1_weighted'][i]\n",
    "        print(f\"  Fold {fold+1}: Acurácia = {acuracia_fold:.4f}, F1-score = {f1_fold:.4f}\")\n",
    "\n",
    "    # Métricas médias\n",
    "    acuracia_media = resultados['mean_test_accuracy'][i]\n",
    "    f1_media = resultados['mean_test_f1_weighted'][i]\n",
    "    acuracia_std = resultados['std_test_accuracy'][i]\n",
    "    f1_std = resultados['std_test_f1_weighted'][i]\n",
    "\n",
    "    print(f\"  Acurácia média: {acuracia_media:.4f}, Desvio padrão: {acuracia_std:.4f}\")\n",
    "    print(f\"  F1-score médio: {f1_media:.4f}, Desvio padrão: {f1_std:.4f}\")\n",
    "    print(\"-\" * 50)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
